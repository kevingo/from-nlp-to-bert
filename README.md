# From NLP to Bert

In this repositoy, I will make some notes on the introductory on NLP to Bert.

## Agenda

- Introduction to NLP
  - Tradition NLP (WordNet / one-hot encoding)
- Basic NLP application
- Basic NLP
  - TF-IDF
- Deep NLP
  - Word2Vec
  - Sequence-to-sequence
  - Attention Model
  - Transformer
- Bert
- Conclusion


## Resources
- [從自然語言處理到文字探勘](https://www.slideshare.net/YiShinChen1/ss-104503736)：Comprehensive introduction from NLP to text mining.
- [CS224n: Natural Language Processing with Deep Learning](http://web.stanford.edu/class/cs224n/)
- [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/pdf/1301.3781.pdf)：The original paper about Word2Vec proposed by Tomas Mikolov. 
- [Seq2seq pay Attention to Self Attention](https://medium.com/@bgg/seq2seq-pay-attention-to-self-attention-part-1-%E4%B8%AD%E6%96%87%E7%89%88-2714bbd92727)
